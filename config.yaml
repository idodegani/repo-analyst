# Repository Configuration
repository:
  path: "./httpx"
  file_extensions:
    - ".py"
    - ".md"
  exclude_dirs:
    - "__pycache__"
    - ".git"
    - "venv"
    - ".pytest_cache"
    - "tests"

# Chunking Configuration
chunking:
  chunk_size: 900        # Characters per chunk (like appd)
  overlap: 100           # Overlap between chunks

# Vector Store Configuration
vector_store:
  index_path: "./data/faiss.index"
  metadata_path: "./data/chunks.jsonl"
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  batch_size: 32            # Batch size for embedding generation

# Retrieval Configuration
retrieval:
  top_k: 5               # Number of chunks to retrieve (adaptive)
  min_score: 0.3         # Minimum similarity score threshold

# Result Validation Configuration
validation:
  require_citations: true      # Ensure answer contains citations
  min_answer_length: 50        # Minimum answer length in characters
  check_grounding: true        # Verify answer is grounded in context

# Conversation Configuration
conversation:
  enable_history: true         # Enable conversation history
  max_history_turns: 5         # Maximum turns to keep in history

# LLM Configuration
llm:
  provider: "openai"
  model: "gpt-4o-mini"
  temperature: 0.1
  max_tokens: 1500
  api_key_env: "open_ai_api_key"

# Judge Configuration
judge:
  enabled: true
  model: "gpt-4o-mini"       # Can use same or different model for independence
  temperature: 0.0           # Lower temp for consistent judging
  max_retries: 1             # Maximum retry attempts for low scores
  confidence_thresholds:
    high: 5                  # Scores >= 5 are good
    medium: 3                # Scores 3-4 get warning

